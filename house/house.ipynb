{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house-prices-advanced-regression-techniques.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  house-prices-advanced-regression-techniques.zip\n",
      "  inflating: dataset/data_description.txt  \n",
      "  inflating: dataset/sample_submission.csv  \n",
      "  inflating: dataset/test.csv        \n",
      "  inflating: dataset/train.csv       \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download - c house-prices-advanced-regression-techniques\n",
    "!unzip house-prices-advanced-regression-techniques.zip - d dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split, WeightedRandomSampler, Subset\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "train_path = os.path.join(current_path, \"./dataset/train.csv\")\n",
    "test_path = os.path.join(current_path, \"./dataset/test.csv\")\n",
    "submission_path = os.path.join(current_path, \"./dataset/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape   \n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg  \\\n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold   \n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2  \\\n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "submisson_df = pd.read_csv(submission_path)\n",
    "train_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1460, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Filter_type(Enum):\n",
    "    HIGH = 0\n",
    "    MID = 1\n",
    "    LOW = 2\n",
    "\n",
    "\n",
    "def transform_df2input(df, mode: Filter_type, nor_mean=0, nor_std=1):\n",
    "    if mode == Filter_type.HIGH:\n",
    "        feature_list = ['LotFrontage', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "                        'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "                        'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    "                        'WoodDeckSF', 'OpenPorchSF', 'SalePrice']\n",
    "    elif mode == Filter_type.MID:\n",
    "        feature_list = ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'TotalBsmtSF',\n",
    "                        '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "                        'GarageYrBlt', 'GarageCars', 'SalePrice']\n",
    "\n",
    "    elif mode == Filter_type.LOW:\n",
    "        feature_list = ['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars',\n",
    "                        'SalePrice']\n",
    "\n",
    "    df_selected = df[feature_list]]\n",
    "    print(len(df_selected))\n",
    "    print(len(df_selected))\n",
    "    numpy_data= df_selected.values\n",
    "\n",
    "    mean= np.nanmean(numpy_data, axis=0)\n",
    "    std= np.nanstd(numpy_data, axis=0)\n",
    "\n",
    "    # 정규화 수행\n",
    "    normalized_array= (((numpy_data - mean) / (std) * nor_std)) + nor_mean\n",
    "    normalized_array= np.nan_to_num(normalized_array)\n",
    "    return numpy_data, normalized_array\n",
    "\n",
    "\n",
    "data, nor_data= transform_df2input(train_df, Filter_type.HIGH)\n",
    "nor_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_type(Enum):\n",
    "    TRAIN = 0\n",
    "    TEST = 1\n",
    "\n",
    "\n",
    "class House_dataset(Dataset):\n",
    "    def __init__(self, df_path, dataset_type: Dataset_type, mode: Filter_type, nor_mean=0, nor_std=1):\n",
    "        self.df_path = df_path\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.nor_mean = nor_mean\n",
    "        self.nor_std = nor_std\n",
    "        self.dataset_type = dataset_type\n",
    "        self.mode = mode\n",
    "        self.input = self._transform_df2input(\n",
    "            self.df, self.mode, self.nor_mean, self.nor_std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.input[0][idx]\n",
    "        if self.dataset_type == Dataset_type.TRAIN:\n",
    "            trg = self.input[1][idx]\n",
    "            return src, trg\n",
    "        else:\n",
    "            return src\n",
    "        return\n",
    "\n",
    "    def _transform_df2input(self, df, mode: Filter_type, dataset_type: Dataset_type, nor_mean=0, nor_std=1):\n",
    "        if mode == Filter_type.HIGH:\n",
    "            feature_list = ['LotFrontage', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "                            'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "                            'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    "                            'WoodDeckSF', 'OpenPorchSF']\n",
    "        elif mode == Filter_type.MID:\n",
    "            feature_list = ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'TotalBsmtSF',\n",
    "                            '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "                            'GarageYrBlt', 'GarageCars']\n",
    "\n",
    "        elif mode == Filter_type.LOW:\n",
    "            feature_list = ['OverallQual',\n",
    "                            'TotalBsmtSF', 'GrLivArea', 'GarageCars']\n",
    "\n",
    "        df_selected = df[feature_list]\n",
    "        if self.dataset_type == Dataset_type.TRAIN:\n",
    "            df_label = df[\"SalePrice\"]\n",
    "            numpy_label = df_label.values\n",
    "        numpy_data = df_selected.values\n",
    "\n",
    "        mean = np.nanmean(numpy_data, axis=0)\n",
    "        std = np.nanstd(numpy_data, axis=0)\n",
    "\n",
    "        # 정규화 수행\n",
    "        normalized_array = (((numpy_data - mean) / (std) * nor_std)) + nor_mean\n",
    "        normalized_array = np.nan_to_num(normalized_array)\n",
    "        if self.dataset_type == Dataset_type.TRAIN:\n",
    "            return (normalized_array, numpy_label)\n",
    "        return normalized_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = House_dataset(\n",
    "    df_path=train_path, dataset_type=Dataset_type.TRAIN, mode=Filter_type.HIGH, nor_mean=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208500"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.input[1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.79196567, 1.65147924, 2.05099379, 1.87866809, 1.51001534,\n",
       "        1.57542484, 0.54069746, 0.20656621, 2.16185159, 1.37033344,\n",
       "        1.78974052, 1.91220977, 0.04877351, 1.99242589, 1.31172464,\n",
       "        0.24782416, 1.21650316]),\n",
       " 208500)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Linear, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        print(input_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = nn.ReLU()(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, num_of_epoch, valid_rate, batch_size,\n",
    "          optimizer, scheduler, criterion, valid_random_seed, patience=3):\n",
    "    torch.manual_seed(valid_random_seed)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    criterion = criterion\n",
    "\n",
    "    train_set_count = int(len(dataset) * valid_rate)\n",
    "    val_set_count = len(dataset) - train_set_count\n",
    "\n",
    "    train_set, val_set = random_split(\n",
    "        dataset, [train_set_count, val_set_count])\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    scheduler = scheduler\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    lrs = []\n",
    "    best_val_loss = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_of_epoch)):\n",
    "        model.train()\n",
    "        correct_train = 0\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # print(data.shape)\n",
    "            # print(data.dtype)\n",
    "            data = data.type(torch.float32)\n",
    "            output = model(data)\n",
    "            loss = torch.sqrt(criterion(output, target))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "            scheduler.step()\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            preds.extend(pred.tolist())\n",
    "            targets.extend(target.tolist())\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, lrs: {}'.format(\n",
    "                    epoch + 1, batch_idx *\n",
    "                    len(data[0]), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item(), lrs[-1]))\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        print(correct_train)\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1} - train loss: {train_losses[-1]}\")\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        targets = []\n",
    "        correct_val = 0\n",
    "        print(len(val_set))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in tqdm(enumerate(val_loader)):\n",
    "                data = data.to(device)\n",
    "                data = data.type(torch.float32)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                _, pred = torch.max(output.data, 1)\n",
    "                preds.extend(pred.tolist())\n",
    "                targets.extend(target.tolist())\n",
    "                # gc.collect()\n",
    "\n",
    "            val_loss = loss.item()\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                current_patience = patience\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "                torch.save(best_model, 'model.pt')\n",
    "            else:\n",
    "                current_patience -= 1\n",
    "                if current_patience < 0:\n",
    "                    print(\"Early Stopping!\")\n",
    "                    is_early_stopping = True\n",
    "\n",
    "            print('Epoch {} finished: train loss = {}, val loss = {}'.format(epoch + 1,\n",
    "                                                                             train_losses[-1], val_losses[-1]))\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1} - Validation loss: {val_loss}\")\n",
    "\n",
    "            if is_early_stopping:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "model = Linear(input_dim=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/15 [00:00<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Long but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[206], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m     12\u001b[0m valid_random_seed \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m---> 13\u001b[0m train(dataset\u001b[39m=\u001b[39;49mtrain_set, valid_rate\u001b[39m=\u001b[39;49mvalid_rate, num_of_epoch\u001b[39m=\u001b[39;49mnum_of_epoch, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     14\u001b[0m       scheduler\u001b[39m=\u001b[39;49mscheduler, criterion\u001b[39m=\u001b[39;49mcriterion, valid_random_seed\u001b[39m=\u001b[39;49mvalid_random_seed)\n",
      "Cell \u001b[0;32mIn[186], line 36\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, num_of_epoch, valid_rate, batch_size, optimizer, scheduler, criterion, valid_random_seed, patience)\u001b[0m\n\u001b[1;32m     34\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     35\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[0;32m---> 36\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m lrs\u001b[39m.\u001b[39mappend(optimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"
     ]
    }
   ],
   "source": [
    "valid_rate = 0.9\n",
    "batch_size = 64\n",
    "learning_rate = 0.0005\n",
    "num_of_epoch = 15\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingWarmupRestarts(\n",
    "    optimizer, first_cycle_steps=4000, cycle_mult=1.0, max_lr=0.001, min_lr=0.0001, warmup_steps=500, gamma=1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "valid_random_seed = 5\n",
    "train(dataset=train_set, valid_rate=valid_rate, num_of_epoch=num_of_epoch, batch_size=64, optimizer=optimizer,\n",
    "      scheduler=scheduler, criterion=criterion, valid_random_seed=valid_random_seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
