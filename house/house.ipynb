{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house-prices-advanced-regression-techniques.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  house-prices-advanced-regression-techniques.zip\n",
      "  inflating: dataset/data_description.txt  \n",
      "  inflating: dataset/sample_submission.csv  \n",
      "  inflating: dataset/test.csv        \n",
      "  inflating: dataset/train.csv       \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download - c house-prices-advanced-regression-techniques\n",
    "!unzip house-prices-advanced-regression-techniques.zip - d dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split, WeightedRandomSampler, Subset\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "train_path = os.path.join(current_path, \"./dataset/train.csv\")\n",
    "test_path = os.path.join(current_path, \"./dataset/test.csv\")\n",
    "submission_path = os.path.join(current_path, \"./dataset/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "len(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1460, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Filter_type(Enum):\n",
    "    HIGH = 0\n",
    "    MID = 1\n",
    "    LOW = 2\n",
    "\n",
    "\n",
    "def transform_df2input(df, mode: Filter_type, nor_mean=0, nor_std=1):\n",
    "    if mode == Filter_type.HIGH:\n",
    "        feature_list = ['LotFrontage', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "                        'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "                        'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    "                        'WoodDeckSF', 'OpenPorchSF', 'SalePrice']\n",
    "    elif mode == Filter_type.MID:\n",
    "        feature_list = ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'TotalBsmtSF',\n",
    "                        '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "                        'GarageYrBlt', 'GarageCars', 'SalePrice']\n",
    "\n",
    "    elif mode == Filter_type.LOW:\n",
    "        feature_list = ['OverallQual', 'TotalBsmtSF', 'GrLivArea', 'GarageCars',\n",
    "                        'SalePrice']\n",
    "\n",
    "    df_selected = df[feature_list]]\n",
    "    numpy_data = df_selected.values\n",
    "\n",
    "    mean = np.nanmean(numpy_data, axis=0)\n",
    "    std = np.nanstd(numpy_data, axis=0)\n",
    "\n",
    "    # 정규화 수행\n",
    "    normalized_array = (((numpy_data - mean) / (std) * nor_std)) + nor_mean\n",
    "    normalized_array = np.nan_to_num(normalized_array)\n",
    "    return numpy_data, normalized_array\n",
    "\n",
    "\n",
    "data, nor_data = transform_df2input(train_df, Filter_type.HIGH)\n",
    "nor_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_type(Enum):\n",
    "    TRAIN = 0\n",
    "    TEST = 1\n",
    "\n",
    "\n",
    "class House_dataset(Dataset):\n",
    "    def __init__(self, df_path, dataset_type: Dataset_type, mode: Filter_type, nor_mean=0, nor_std=1):\n",
    "        self.df_path = df_path\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.nor_mean = nor_mean\n",
    "        self.nor_std = nor_std\n",
    "        self.dataset_type = dataset_type\n",
    "        self.mode = mode\n",
    "        self.input = self._transform_df2input(\n",
    "            self.df, self.mode, self.nor_mean, self.nor_std)\n",
    "        self.trg_mean, self.trg_std = self._trg_mean_std(self.input[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.input[0][idx] if self.dataset_type == Dataset_type.TRAIN else self.input[idx]\n",
    "        if self.dataset_type == Dataset_type.TRAIN:\n",
    "            trg = self.input[1][idx]\n",
    "            trg = (((trg - self.trg_mean) / (self.trg_std)\n",
    "                   * self.nor_std)) + self.nor_mean\n",
    "            trg = np.nan_to_num(trg)\n",
    "            return src, trg\n",
    "        else:\n",
    "            return src\n",
    "\n",
    "    def _trg_mean_std(self, trg_list):\n",
    "        mean = np.nanmean(trg_list, axis=0)\n",
    "        std = np.nanstd(trg_list, axis=0)\n",
    "        return mean, std\n",
    "\n",
    "    def _transform_df2input(self, df, mode: Filter_type, dataset_type: Dataset_type, nor_mean=0, nor_std=1):\n",
    "        if mode == Filter_type.HIGH:\n",
    "            feature_list = ['LotFrontage', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "                            'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "                            'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    "                            'WoodDeckSF', 'OpenPorchSF']\n",
    "        elif mode == Filter_type.MID:\n",
    "            feature_list = ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'TotalBsmtSF',\n",
    "                            '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "                            'GarageYrBlt', 'GarageCars']\n",
    "\n",
    "        elif mode == Filter_type.LOW:\n",
    "            feature_list = ['OverallQual',\n",
    "                            'TotalBsmtSF', 'GrLivArea', 'GarageCars']\n",
    "\n",
    "        df_selected = df[feature_list]\n",
    "        if self.dataset_type == Dataset_type.TRAIN:\n",
    "            df_label = df[\"SalePrice\"]\n",
    "            numpy_label = df_label.values\n",
    "        numpy_data = df_selected.values\n",
    "\n",
    "        mean = np.nanmean(numpy_data, axis=0)\n",
    "        std = np.nanstd(numpy_data, axis=0)\n",
    "\n",
    "        # 정규화 수행\n",
    "        normalized_array = (((numpy_data - mean) / (std) * nor_std)) + nor_mean\n",
    "        normalized_array = np.nan_to_num(normalized_array)\n",
    "        if self.dataset_type == Dataset_type.TRAIN:\n",
    "            return (normalized_array, numpy_label)\n",
    "        return normalized_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = House_dataset(\n",
    "    df_path=train_path, dataset_type=Dataset_type.TRAIN, mode=Filter_type.HIGH, nor_mean=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8472732197365056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.79196567, 1.65147924, 2.05099379, 1.87866809, 1.51001534,\n",
       "        1.57542484, 0.54069746, 0.20656621, 2.16185159, 1.37033344,\n",
       "        1.78974052, 1.91220977, 0.04877351, 1.99242589, 1.31172464,\n",
       "        0.24782416, 1.21650316]),\n",
       " 0.8472732197365056)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.79196567, 1.65147924, 2.05099379, 1.87866809, 1.51001534,\n",
       "        1.57542484, 0.54069746, 0.20656621, 2.16185159, 1.37033344,\n",
       "        1.78974052, 1.91220977, 0.04877351, 1.99242589, 1.31172464,\n",
       "        0.24782416, 1.21650316]),\n",
       " 208500)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Linear, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = nn.ReLU()(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def train(dataset, num_of_epoch, valid_rate, batch_size,\n",
    "          optimizer, scheduler, criterion, valid_random_seed, patience=3):\n",
    "    torch.manual_seed(valid_random_seed)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    criterion = criterion\n",
    "\n",
    "    train_set_count = int(len(dataset) * valid_rate)\n",
    "    val_set_count = len(dataset) - train_set_count\n",
    "\n",
    "    train_set, val_set = random_split(\n",
    "        dataset, [train_set_count, val_set_count])\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    scheduler = scheduler\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    lrs = []\n",
    "    best_val_loss = sys.maxsize\n",
    "    current_patience = patience\n",
    "    is_early_stopping = False\n",
    "\n",
    "    for epoch in range(num_of_epoch):\n",
    "        model.train()\n",
    "        correct_train = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # print(data.shape)\n",
    "            # print(data.dtype)\n",
    "            data = data.type(torch.float32)\n",
    "            output = model(data).float()\n",
    "            target = target.float()\n",
    "            loss = torch.sqrt(criterion(output, target)).float()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "            scheduler.step()\n",
    "            # _, pred = torch.max(output.data, 1)\n",
    "            # preds.extend(pred.tolist())\n",
    "            # targets.extend(target.tolist())\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, lrs: {}'.format(\n",
    "                    epoch + 1, batch_idx *\n",
    "                    len(data[0]), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item(), lrs[-1]))\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1} - train loss: {train_losses[-1]}\")\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        targets = []\n",
    "        correct_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                data = data.to(device)\n",
    "                data = data.type(torch.float32)\n",
    "                output = model(data).float()\n",
    "                target = target.float()\n",
    "                loss = torch.sqrt(criterion(output, target)).float()\n",
    "                # _, pred = torch.max(output.data, 1)\n",
    "                # preds.extend(pred.tolist())\n",
    "                # targets.extend(target.tolist())\n",
    "                # gc.collect()\n",
    "\n",
    "            val_loss = loss.item()\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                current_patience = patience\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "                torch.save(best_model, 'model.pt')\n",
    "            else:\n",
    "                current_patience -= 1\n",
    "                if current_patience < 0:\n",
    "                    # print(\"Early Stopping!\")\n",
    "                    is_early_stopping = False\n",
    "\n",
    "            print('Epoch {} finished: train loss = {}, val loss = {}'.format(epoch + 1,\n",
    "                                                                             train_losses[-1], val_losses[-1]))\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1} - Validation loss: {val_loss}\")\n",
    "            print(\"\\n\\n\\n\")\n",
    "\n",
    "            if is_early_stopping:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(train_set[0][0])\n",
    "print(input_dim)\n",
    "model = Linear(input_dim=input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[332], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mmodel.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pt'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x1 and 17x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[335], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m     12\u001b[0m valid_random_seed \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m---> 13\u001b[0m train(dataset\u001b[39m=\u001b[39;49mtrain_set, valid_rate\u001b[39m=\u001b[39;49mvalid_rate, num_of_epoch\u001b[39m=\u001b[39;49mnum_of_epoch, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     14\u001b[0m       scheduler\u001b[39m=\u001b[39;49mscheduler, criterion\u001b[39m=\u001b[39;49mcriterion, valid_random_seed\u001b[39m=\u001b[39;49mvalid_random_seed)\n",
      "Cell \u001b[0;32mIn[333], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, num_of_epoch, valid_rate, batch_size, optimizer, scheduler, criterion, valid_random_seed, patience)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m# print(data.shape)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# print(data.dtype)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 39\u001b[0m output \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     40\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     41\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(criterion(output, target))\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[330], line 13\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU()(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n\u001b[0;32m---> 13\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU()(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     14\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU()(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU()(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/competition_study/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x1 and 17x1)"
     ]
    }
   ],
   "source": [
    "valid_rate = 0.9\n",
    "batch_size = 64\n",
    "learning_rate = 0.0005\n",
    "num_of_epoch = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingWarmupRestarts(\n",
    "    optimizer, first_cycle_steps=4000, cycle_mult=1.0, max_lr=0.001, min_lr=0.0001, warmup_steps=500, gamma=1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "valid_random_seed = 5\n",
    "train(dataset=train_set, valid_rate=valid_rate, num_of_epoch=num_of_epoch, batch_size=64, optimizer=optimizer,\n",
    "      scheduler=scheduler, criterion=criterion, valid_random_seed=valid_random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, batch_size, trg_mean, trg_std, nor_mean, nor_std):\n",
    "\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                             shuffle=False)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            data = data.type(torch.float32)\n",
    "            output = model(data).float()\n",
    "            output = trg_std * nor_std * (output - nor_mean) + trg_mean\n",
    "\n",
    "            pred_list.extend(list(output))\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = House_dataset(\n",
    "    df_path=test_path, dataset_type=Dataset_type.TEST, mode=Filter_type.LOW, nor_mean=0.5)\n",
    "\n",
    "result = test(dataset=test_set, batch_size=batch_size, trg_mean=train_set.trg_mean,\n",
    "              trg_std=train_set.trg_std, nor_mean=train_set.nor_mean, nor_std=train_set.nor_std)\n",
    "\n",
    "# result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>169277.052498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>187758.393989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>183583.683570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>179317.477511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>150730.079977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  169277.052498\n",
       "1  1462  187758.393989\n",
       "2  1463  183583.683570\n",
       "3  1464  179317.477511\n",
       "4  1465  150730.079977"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>173835.71875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>176700.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>181659.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>179474.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>175534.34375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id     SalePrice\n",
       "0  1461  173835.71875\n",
       "1  1462  176700.53125\n",
       "2  1463  181659.53125\n",
       "3  1464  179474.75000\n",
       "4  1465  175534.34375"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[\"SalePrice\"] = [element.item() for element in result]\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission_result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
